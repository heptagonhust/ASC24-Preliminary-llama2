2023-12-24 03:04:21,845	INFO usage_lib.py:421 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2023-12-24 03:04:21,845	INFO scripts.py:744 -- Local node IP: 192.168.251.101
2023-12-24 03:04:24,949	SUCC scripts.py:781 -- --------------------
2023-12-24 03:04:24,949	SUCC scripts.py:782 -- Ray runtime started.
2023-12-24 03:04:24,949	SUCC scripts.py:783 -- --------------------
2023-12-24 03:04:24,949	INFO scripts.py:785 -- Next steps
2023-12-24 03:04:24,949	INFO scripts.py:788 -- To add another node to this Ray cluster, run
2023-12-24 03:04:24,949	INFO scripts.py:791 --   ray start --address='192.168.251.101:6379'
2023-12-24 03:04:24,949	INFO scripts.py:800 -- To connect to this Ray cluster:
2023-12-24 03:04:24,951	INFO scripts.py:802 -- import ray
2023-12-24 03:04:24,951	INFO scripts.py:803 -- ray.init(_node_ip_address='192.168.251.101')
2023-12-24 03:04:24,951	INFO scripts.py:834 -- To terminate the Ray runtime, run
2023-12-24 03:04:24,951	INFO scripts.py:835 --   ray stop
2023-12-24 03:04:24,952	INFO scripts.py:838 -- To view the status of the cluster, use
2023-12-24 03:04:24,952	INFO scripts.py:839 --   ray status
2023-12-24 03:04:26,698	INFO scripts.py:926 -- Local node IP: 192.168.251.105
2023-12-24 03:04:26,733	SUCC scripts.py:939 -- --------------------
2023-12-24 03:04:26,734	SUCC scripts.py:940 -- Ray runtime started.
2023-12-24 03:04:26,734	SUCC scripts.py:941 -- --------------------
2023-12-24 03:04:26,734	INFO scripts.py:943 -- To terminate the Ray runtime, run
2023-12-24 03:04:26,734	INFO scripts.py:944 --   ray stop
2023-12-24 03:04:26,738	INFO scripts.py:926 -- Local node IP: 192.168.251.104
2023-12-24 03:04:26,771	SUCC scripts.py:939 -- --------------------
2023-12-24 03:04:26,771	SUCC scripts.py:940 -- Ray runtime started.
2023-12-24 03:04:26,771	SUCC scripts.py:941 -- --------------------
2023-12-24 03:04:26,771	INFO scripts.py:943 -- To terminate the Ray runtime, run
2023-12-24 03:04:26,772	INFO scripts.py:944 --   ray stop
INFO 12-24 03:05:15 llm_engine.py:73] Initializing an LLM engine with config: model='/data/70B-chat-hf', tokenizer='/data/70B-chat-hf', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867315 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,veth
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867315 [0] NCCL INFO Bootstrap : Using ens25f0:192.168.250.101<0>
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867315 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867315 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867315 [0] NCCL INFO cudaDriverVersion 12020
[36m(RayWorkerVllm pid=867315)[0m NCCL version 2.18.1+cuda12.1
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO NET/IB : Using [0]mlx4_1:1/IB [1]mlx4_0:1/IB ; OOB ens25f0:192.168.250.103<0>
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Using network IB
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] 2/-1/-1->3->4 [2] -1/-1/-1->3->2 [3] 2/1/-1->3->-1
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO P2P Chunksize set to 131072
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 00/0 : 3[b1000] -> 4[4b000] [send] via NET/IB/1
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 01/0 : 3[b1000] -> 4[4b000] [send] via NET/IB/0
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 02/0 : 3[b1000] -> 4[4b000] [send] via NET/IB/1
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 03/0 : 3[b1000] -> 4[4b000] [send] via NET/IB/0
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Connected all rings
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 03/0 : 1[b1000] -> 3[b1000] [receive] via NET/IB/0
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 03/0 : 3[b1000] -> 1[b1000] [send] via NET/IB/0
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 01/0 : 4[4b000] -> 3[b1000] [receive] via NET/IB/0
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 00 : 3[b1000] -> 2[4b000] via SHM/direct/direct
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 01 : 3[b1000] -> 2[4b000] via SHM/direct/direct
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 02 : 3[b1000] -> 2[4b000] via SHM/direct/direct
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Channel 03 : 3[b1000] -> 2[4b000] via SHM/direct/direct
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO Connected all trees
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO threadThresholds 8/8/64 | 48/8/64 | 512 | 512
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO 4 coll channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201730 [1] NCCL INFO comm 0x9395e10 rank 3 nranks 6 cudaDev 1 busId b1000 commId 0x1fc08ddfee8c6522 - Init COMPLETE
[36m(RayWorkerVllm pid=201563, ip=192.168.251.105)[0m hepgpu3:201563:201729 [0] NCCL INFO Setting affinity for GPU 0 to 01,00000000,00000001
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868000 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,veth[32m [repeated 10x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:867316 [1] NCCL INFO Bootstrap : Using ens25f0:192.168.250.101<0>[32m [repeated 5x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:867316 [1] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory[32m [repeated 5x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:867316 [1] NCCL INFO NET/Plugin : No plugin found, using internal implementation[32m [repeated 5x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:867316 [1] NCCL INFO cudaDriverVersion 12020[32m [repeated 5x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO Channel 00/04 :    0   1   2   3   4   5
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO Channel 01/04 :    0   1   2   3   4   5
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO Channel 02/04 :    0   1   2   3   4   5
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO Channel 03/04 :    0   1   2   3   4   5
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO NET/IB : Using [0]mlx5_1:1/IB [1]mlx5_0:1/IB ; OOB ens25f0:192.168.250.101<0>[32m [repeated 5x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO Using network IB[32m [repeated 6x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0[32m [repeated 6x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO P2P Chunksize set to 131072[32m [repeated 6x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO Channel 03/0 : 0[4b000] -> 5[b1000] [send] via NET/IB/0[32m [repeated 21x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO Connected all rings[32m [repeated 6x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO Channel 02/0 : 2[4b000] -> 0[4b000] [receive] via NET/IB/1[32m [repeated 24x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO Channel 01 : 1[b1000] -> 0[4b000] via SHM/direct/direct[32m [repeated 22x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO Connected all trees[32m [repeated 6x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512[32m [repeated 6x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer[32m [repeated 6x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868077 [1] NCCL INFO comm 0x177cdc50 rank 1 nranks 2 cudaDev 1 busId b1000 commId 0xcdfa72cbc1a507ae - Init COMPLETE[32m [repeated 6x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO Setting affinity for GPU 0 to 01,00000000,00000001[32m [repeated 2x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867999 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ^lo,docker,veth
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868076 [0] NCCL INFO Channel 00/02 :    0   1
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868076 [0] NCCL INFO Channel 01/02 :    0   1
[36m(RayWorkerVllm pid=867316)[0m NCCL version 2.18.1+cuda12.1
[36m(RayWorkerVllm pid=867315)[0m 
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] transport.cc:174 NCCL WARN Cuda failure 'invalid argument'
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] NCCL INFO init.cc:1032 -> 1
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] NCCL INFO init.cc:1309 -> 1
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] NCCL INFO group.cc:64 -> 1 [Async thread]
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867315 [0] NCCL INFO group.cc:422 -> 1
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:867315 [0] NCCL INFO group.cc:106 -> 1
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868086 [0] NCCL INFO misc/socket.cc:46 -> 3
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868086 [0] NCCL INFO misc/socket.cc:57 -> 3
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868086 [0] NCCL INFO misc/socket.cc:769 -> 3
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868086 [0] NCCL INFO proxy.cc:1333 -> 3
[36m(RayWorkerVllm pid=867315)[0m 
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868086 [0] proxy.cc:1484 NCCL WARN [Service thread] Error encountered progressing operation=Connect, res=3, closing connection
[36m(RayWorkerVllm pid=867315)[0m 
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868086 [0] proxy.cc:1518 NCCL WARN [Proxy Service 0] Failed to execute operation Connect from rank 0, retcode 3
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] NCCL INFO Using network IB[32m [repeated 5x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1[32m [repeated 5x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] NCCL INFO P2P Chunksize set to 131072[32m [repeated 5x across cluster][0m
[36m(RayWorkerVllm pid=867316)[0m hepgpu1:867316:868098 [1] NCCL INFO Channel 01/1 : 0[b1000] -> 1[b1000] [send] via NET/IB/0/Shared[32m [repeated 10x across cluster][0m
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201758 [1] NCCL INFO Connected all rings[32m [repeated 3x across cluster][0m
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201763 [1] NCCL INFO Channel 01/1 : 0[b1000] -> 1[b1000] [receive] via NET/IB/0/Shared[32m [repeated 10x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868076 [0] NCCL INFO Channel 01 : 0[4b000] -> 1[b1000] via SHM/direct/direct[32m [repeated 2x across cluster][0m
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201758 [1] NCCL INFO Connected all trees[32m [repeated 3x across cluster][0m
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201758 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512[32m [repeated 3x across cluster][0m
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201758 [1] NCCL INFO 2 coll channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer[32m [repeated 3x across cluster][0m
[36m(RayWorkerVllm pid=201564, ip=192.168.251.105)[0m hepgpu3:201564:201758 [1] NCCL INFO comm 0x10331200 rank 1 nranks 2 cudaDev 1 busId b1000 commId 0xe6e00a2c8d98dcc9 - Init COMPLETE[32m [repeated 3x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] NCCL INFO Setting affinity for GPU 0 to 01,00000000,00000001[32m [repeated 3x across cluster][0m
[36m(RayWorkerVllm pid=867315)[0m hepgpu1:867315:868083 [0] NCCL INFO Channel 01/02 :    0   1[32m [repeated 4x across cluster][0m
2023-12-24 03:05:50,353	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --store_socket_name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=192.168.251.104 --maximum_startup_concurrency=128 --static_resource_list=node:192.168.251.104,1.0,accelerator_type:L40,1,CPU,128,GPU,2,memory,591737315328,object_store_memory,200000000000 "--python_worker_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/workers/setup_worker.py /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=192.168.251.104 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --raylet-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=61142 --runtime-env-agent-port=64242 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=64242 --gcs-address=192.168.251.101:6379 --session-name=session_2023-12-24_03-04-21_846517_862552 --temp-dir=/tmp/ray --webui= --cluster-id=e9021d540cdd416fb258fc37f1fb27da949ece73c174e2e000e265d5 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" --java_worker_command= --cpp_worker_command= --native_library_path=/data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/cpp/lib --temp_dir=/tmp/ray --session_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --log_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --resource_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/runtime_resources --metrics-agent-port=61142 --metrics_export_port=47591 --runtime_env_agent_port=64242 --object_store_memory=200000000000 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=192.168.251.101:6379 --session-name=session_2023-12-24_03-04-21_846517_862552 --labels= --cluster-id=e9021d540cdd416fb258fc37f1fb27da949ece73c174e2e000e265d5 --num_prestart_python_workers=128 "--dashboard_agent_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/dashboard/agent.py --node-ip-address=192.168.251.104 --metrics-export-port=47591 --dashboard-agent-port=61142 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --raylet-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --temp-dir=/tmp/ray --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --log-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2023-12-24_03-04-21_846517_862552 --gcs-address=192.168.251.101:6379 --minimal" "--runtime_env_agent_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/runtime_env/agent/main.py --node-ip-address=192.168.251.104 --runtime-env-agent-port=64242 --gcs-address=192.168.251.101:6379 --runtime-env-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/runtime_resources --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --log-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --temp-dir=/tmp/ray"` (via SIGTERM)
2023-12-24 03:05:50,533	INFO scripts.py:1121 -- 1/1 stopped.2023-12-24 03:05:50,746	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --logs-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --gcs-address=192.168.251.101:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2023-12-24 03:05:50,751	VINFO scripts.py:1099 -- Attempted to stop `/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --logs-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --gcs-address=192.168.251.101:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5`, but process was already dead.
2023-12-24 03:05:50,755	INFO scripts.py:1121 -- 1/1 stopped.2023-12-24 03:05:50,902	SUCC scripts.py:1166 -- Stopped all 2 Ray processes.
2023-12-24 03:05:50,409	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --store_socket_name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=192.168.251.105 --maximum_startup_concurrency=128 --static_resource_list=node:192.168.251.105,1.0,accelerator_type:L40,1,CPU,128,GPU,2,memory,585786667008,object_store_memory,200000000000 "--python_worker_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/workers/setup_worker.py /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=192.168.251.105 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --raylet-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=42158 --runtime-env-agent-port=64887 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=64887 --gcs-address=192.168.251.101:6379 --session-name=session_2023-12-24_03-04-21_846517_862552 --temp-dir=/tmp/ray --webui= --cluster-id=e9021d540cdd416fb258fc37f1fb27da949ece73c174e2e000e265d5 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" --java_worker_command= --cpp_worker_command= --native_library_path=/data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/cpp/lib --temp_dir=/tmp/ray --session_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --log_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --resource_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/runtime_resources --metrics-agent-port=42158 --metrics_export_port=56660 --runtime_env_agent_port=64887 --object_store_memory=200000000000 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=192.168.251.101:6379 --session-name=session_2023-12-24_03-04-21_846517_862552 --labels= --cluster-id=e9021d540cdd416fb258fc37f1fb27da949ece73c174e2e000e265d5 --num_prestart_python_workers=128 "--dashboard_agent_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/dashboard/agent.py --node-ip-address=192.168.251.105 --metrics-export-port=56660 --dashboard-agent-port=42158 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --raylet-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --temp-dir=/tmp/ray --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --log-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2023-12-24_03-04-21_846517_862552 --gcs-address=192.168.251.101:6379 --minimal" "--runtime_env_agent_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/runtime_env/agent/main.py --node-ip-address=192.168.251.105 --runtime-env-agent-port=64887 --gcs-address=192.168.251.101:6379 --runtime-env-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/runtime_resources --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --log-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --temp-dir=/tmp/ray"` (via SIGTERM)
2023-12-24 03:05:50,661	INFO scripts.py:1121 -- 1/1 stopped.2023-12-24 03:05:50,826	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --logs-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --gcs-address=192.168.251.101:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2023-12-24 03:05:50,832	VINFO scripts.py:1091 -- Send termination request to `ray::RayWorkerVllm "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""` (via SIGTERM)
2023-12-24 03:05:50,836	VINFO scripts.py:1099 -- Attempted to stop `/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --logs-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --gcs-address=192.168.251.101:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5`, but process was already dead.
2023-12-24 03:05:51,379	INFO scripts.py:1121 -- 1/2 stopped.2023-12-24 03:05:52,032	INFO scripts.py:1121 -- 2/2 stopped.2023-12-24 03:05:52,179	SUCC scripts.py:1166 -- Stopped all 3 Ray processes.
2023-12-24 03:05:51,160	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --store_socket_name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=192.168.251.101 --maximum_startup_concurrency=128 --static_resource_list=node:192.168.251.101,1.0,node:__internal_head__,1.0,accelerator_type:L40,1,CPU,128,GPU,2,memory,467111410688,object_store_memory,200000000000 "--python_worker_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/workers/setup_worker.py /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/workers/default_worker.py --node-ip-address=192.168.251.101 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --raylet-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --redis-address=None --temp-dir=/tmp/ray --metrics-agent-port=51629 --runtime-env-agent-port=38604 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --runtime-env-agent-port=38604 --gcs-address=192.168.251.101:6379 --session-name=session_2023-12-24_03-04-21_846517_862552 --temp-dir=/tmp/ray --webui= --cluster-id=e9021d540cdd416fb258fc37f1fb27da949ece73c174e2e000e265d5 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/workers/setup_worker.py -Dray.address=192.168.251.101:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store -Dray.raylet.socket-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet -Dray.redis.password= -Dray.node-ip=192.168.251.101 -Dray.home=/data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/../.. -Dray.logging.dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs -Dray.session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/cpp/lib --temp_dir=/tmp/ray --session_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --log_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --resource_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/runtime_resources --metrics-agent-port=51629 --metrics_export_port=50385 --runtime_env_agent_port=38604 --object_store_memory=200000000000 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=192.168.251.101:6379 --session-name=session_2023-12-24_03-04-21_846517_862552 --labels= --cluster-id=e9021d540cdd416fb258fc37f1fb27da949ece73c174e2e000e265d5 --head --num_prestart_python_workers=128 "--dashboard_agent_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/dashboard/agent.py --node-ip-address=192.168.251.101 --metrics-export-port=50385 --dashboard-agent-port=51629 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/plasma_store --raylet-name=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/sockets/raylet --temp-dir=/tmp/ray --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --log-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2023-12-24_03-04-21_846517_862552 --gcs-address=192.168.251.101:6379 --minimal" "--runtime_env_agent_command=/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/runtime_env/agent/main.py --node-ip-address=192.168.251.101 --runtime-env-agent-port=38604 --gcs-address=192.168.251.101:6379 --runtime-env-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/runtime_resources --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --log-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --temp-dir=/tmp/ray" --node-name=192.168.251.101` (via SIGTERM)
2023-12-24 03:05:51,977	INFO scripts.py:1121 -- 1/1 stopped.2023-12-24 03:05:52,231	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/autoscaler/_private/monitor.py --logs-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=192.168.251.101:6379 --monitor-ip=192.168.251.101` (via SIGTERM)
2023-12-24 03:05:52,232	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --logs-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --gcs-address=192.168.251.101:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2023-12-24 03:05:52,239	VINFO scripts.py:1099 -- Attempted to stop `/data/asc24llama/miniconda3/envs/llama_new/bin/python -u /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/_private/log_monitor.py --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --logs-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --gcs-address=192.168.251.101:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5`, but process was already dead.
2023-12-24 03:05:52,242	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/bin/python /data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/dashboard/dashboard.py --host=127.0.0.1 --port=8265 --port-retries=0 --temp-dir=/tmp/ray --log-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --session-dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=192.168.251.101:6379 --node-ip-address=192.168.251.101 --minimal` (via SIGTERM)
2023-12-24 03:05:52,618	INFO scripts.py:1121 -- 1/3 stopped.2023-12-24 03:05:52,619	INFO scripts.py:1121 -- 2/3 stopped.2023-12-24 03:05:52,831	INFO scripts.py:1121 -- 3/3 stopped.2023-12-24 03:05:52,998	VINFO scripts.py:1091 -- Send termination request to `/data/asc24llama/miniconda3/envs/llama_new/lib/python3.9/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/tmp/ray/session_2023-12-24_03-04-21_846517_862552/logs --config_list=eyJvYmplY3Rfc3BpbGxpbmdfY29uZmlnIjogIntcInR5cGVcIjogXCJmaWxlc3lzdGVtXCIsIFwicGFyYW1zXCI6IHtcImRpcmVjdG9yeV9wYXRoXCI6IFwiL3RtcC9yYXkvc2Vzc2lvbl8yMDIzLTEyLTI0XzAzLTA0LTIxXzg0NjUxN184NjI1NTJcIn19IiwgImlzX2V4dGVybmFsX3N0b3JhZ2VfdHlwZV9mcyI6IHRydWV9 --gcs_server_port=6379 --metrics-agent-port=51629 --node-ip-address=192.168.251.101 --session-name=session_2023-12-24_03-04-21_846517_862552` (via SIGTERM)
2023-12-24 03:05:53,393	INFO scripts.py:1121 -- 1/1 stopped.2023-12-24 03:05:53,393	SUCC scripts.py:1166 -- Stopped all 5 Ray processes.
